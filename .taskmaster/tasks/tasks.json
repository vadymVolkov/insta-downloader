{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Setup Basic FastAPI Project Structure",
        "description": "Create the initial FastAPI project structure with the recommended architecture including routers, services, and schemas directories.",
        "details": "1. Initialize a new Python project\n2. Install required dependencies: fastapi, uvicorn, pydantic, instaloader\n3. Create the following directory structure:\n   - app/\n     - main.py (FastAPI application entry point)\n     - routers/\n       - __init__.py\n     - services/\n       - __init__.py\n     - schemas/\n       - __init__.py\n     - media/ (for storing downloaded files)\n4. Setup basic FastAPI application in main.py:\n```python\nfrom fastapi import FastAPI\nfrom fastapi.staticfiles import StaticFiles\n\napp = FastAPI(title=\"Instagram Downloader API\")\n\n# Will be mounted after implementing the static files functionality\n# app.mount(\"/static\", StaticFiles(directory=\"media\"), name=\"static\")\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Instagram Downloader API\"}\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True)\n```\n5. Create requirements.txt with all dependencies",
        "testStrategy": "1. Verify the project structure is correctly set up\n2. Run the application with `uvicorn app.main:app --reload`\n3. Test the root endpoint with a GET request to / and verify it returns the expected JSON response\n4. Ensure all directories are created and accessible",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "Implement Pydantic Schemas for Data Validation",
        "description": "Create Pydantic models for request and response validation, including Instagram URL validation and response structure.",
        "details": "Create the following schemas in the schemas directory:\n\n1. Create `schemas/requests.py`:\n```python\nfrom pydantic import BaseModel, HttpUrl, validator\nimport re\n\nclass DownloadRequest(BaseModel):\n    url: HttpUrl\n    \n    @validator('url')\n    def validate_instagram_url(cls, v):\n        # Basic Instagram URL validation pattern\n        pattern = r'^https?://(www\\.)?instagram\\.com/p/[\\w-]+/?.*$'\n        if not re.match(pattern, str(v)):\n            raise ValueError('URL must be a valid Instagram post URL')\n        return v\n```\n\n2. Create `schemas/responses.py`:\n```python\nfrom pydantic import BaseModel\nfrom typing import List, Optional\nfrom datetime import datetime\n\nclass CommentModel(BaseModel):\n    user: str\n    text: str\n\nclass DownloadResponse(BaseModel):\n    author: str\n    description: Optional[str] = None\n    created_at: datetime\n    video_url: str\n    comments: Optional[List[CommentModel]] = []\n```",
        "testStrategy": "1. Write unit tests for the Pydantic models\n2. Test URL validation with valid and invalid Instagram URLs\n3. Verify that the response model correctly validates sample data\n4. Test edge cases like empty comments list and missing optional fields",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "Integrate Instaloader Library",
        "description": "Set up the instaloader library to connect to Instagram and download video content from posts.",
        "details": "1. Create a service module for Instagram interactions in `services/instagram_service.py`:\n```python\nimport instaloader\nimport os\nimport uuid\nfrom datetime import datetime\nfrom typing import Dict, List, Tuple, Any\n\nclass InstagramService:\n    def __init__(self, media_dir: str = \"media\"):\n        self.loader = instaloader.Instaloader(\n            download_videos=True,\n            download_video_thumbnails=False,\n            download_geotags=False,\n            download_comments=True,\n            save_metadata=True,\n            compress_json=False\n        )\n        self.media_dir = media_dir\n        os.makedirs(media_dir, exist_ok=True)\n        \n    def extract_shortcode_from_url(self, url: str) -> str:\n        # Extract the shortcode from an Instagram URL\n        # Example: https://www.instagram.com/p/ABC123/ -> ABC123\n        parts = url.strip(\"/\").split(\"/\")\n        p_index = parts.index(\"p\") if \"p\" in parts else -1\n        if p_index != -1 and p_index + 1 < len(parts):\n            return parts[p_index + 1]\n        raise ValueError(\"Could not extract shortcode from URL\")\n        \n    async def download_post(self, url: str) -> Tuple[str, Dict[str, Any]]:\n        \"\"\"Download a post and return the file path and metadata\"\"\"\n        try:\n            shortcode = self.extract_shortcode_from_url(url)\n            post = instaloader.Post.from_shortcode(self.loader.context, shortcode)\n            \n            # Generate a unique filename\n            filename = f\"{uuid.uuid4()}.mp4\"\n            filepath = os.path.join(self.media_dir, filename)\n            \n            # Download the video\n            if post.is_video:\n                self.loader.download_post(post, target=self.media_dir)\n                # Rename the downloaded file to our unique filename\n                # Find the video file that was just downloaded\n                for file in os.listdir(self.media_dir):\n                    if file.endswith(\".mp4\") and shortcode in file:\n                        os.rename(\n                            os.path.join(self.media_dir, file),\n                            filepath\n                        )\n                        break\n            else:\n                raise ValueError(\"The provided URL does not contain a video\")\n                \n            # Extract metadata\n            metadata = {\n                \"author\": post.owner_username,\n                \"description\": post.caption if post.caption else \"\",\n                \"created_at\": post.date,\n                \"video_url\": f\"/static/{filename}\",\n                \"comments\": self._extract_comments(post)\n            }\n            \n            return filename, metadata\n        except Exception as e:\n            raise Exception(f\"Error downloading Instagram post: {str(e)}\")\n    \n    def _extract_comments(self, post: instaloader.Post) -> List[Dict[str, str]]:\n        \"\"\"Extract comments from a post\"\"\"\n        comments = []\n        try:\n            for comment in post.get_comments():\n                comments.append({\n                    \"user\": comment.owner.username,\n                    \"text\": comment.text\n                })\n        except Exception:\n            # If comments can't be fetched, return empty list\n            pass\n        return comments\n```",
        "testStrategy": "1. Create unit tests for the InstagramService class\n2. Test URL parsing with different Instagram URL formats\n3. Mock instaloader responses to test the download functionality\n4. Verify that metadata extraction works correctly\n5. Test error handling for invalid URLs and non-video posts",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "Implement Static File Serving",
        "description": "Configure FastAPI to serve static files from the media directory, allowing access to downloaded videos via HTTP.",
        "details": "1. Update the main.py file to mount the StaticFiles middleware:\n```python\nfrom fastapi import FastAPI\nfrom fastapi.staticfiles import StaticFiles\nimport os\n\n# Create media directory if it doesn't exist\nos.makedirs(\"media\", exist_ok=True)\n\napp = FastAPI(title=\"Instagram Downloader API\")\n\n# Mount the static files directory\napp.mount(\"/static\", StaticFiles(directory=\"media\"), name=\"static\")\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Instagram Downloader API\"}\n```\n\n2. Ensure the media directory has proper permissions for the web server to read/write files\n\n3. Add a utility function in a new file `utils/file_management.py` to handle file cleanup:\n```python\nimport os\nimport time\nfrom datetime import datetime, timedelta\n\ndef cleanup_old_files(directory: str, max_age_days: int = 7):\n    \"\"\"Remove files older than max_age_days from the specified directory\"\"\"\n    now = time.time()\n    max_age_seconds = max_age_days * 24 * 60 * 60\n    \n    for filename in os.listdir(directory):\n        file_path = os.path.join(directory, filename)\n        if os.path.isfile(file_path):\n            file_age = now - os.path.getmtime(file_path)\n            if file_age > max_age_seconds:\n                try:\n                    os.remove(file_path)\n                except Exception as e:\n                    print(f\"Error removing {file_path}: {e}\")\n```",
        "testStrategy": "1. Test that static files are accessible via the /static/ URL path\n2. Upload a test file to the media directory and verify it can be accessed\n3. Test the file cleanup utility with files of different ages\n4. Verify that file permissions are set correctly for the web server",
        "priority": "medium",
        "dependencies": [
          1
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 5,
        "title": "Create Download API Endpoint",
        "description": "Implement the main POST /api/download/ endpoint that accepts an Instagram URL and returns video metadata and download link.",
        "details": "1. Create a router file in `routers/download.py`:\n```python\nfrom fastapi import APIRouter, HTTPException, Depends\nfrom ..schemas.requests import DownloadRequest\nfrom ..schemas.responses import DownloadResponse\nfrom ..services.instagram_service import InstagramService\nimport logging\n\nrouter = APIRouter(prefix=\"/api\", tags=[\"download\"])\nlogger = logging.getLogger(__name__)\n\n# Dependency to get the Instagram service\ndef get_instagram_service():\n    return InstagramService()\n\n@router.post(\"/download/\", response_model=DownloadResponse)\nasync def download_instagram_video(request: DownloadRequest, service: InstagramService = Depends(get_instagram_service)):\n    try:\n        logger.info(f\"Processing download request for URL: {request.url}\")\n        filename, metadata = await service.download_post(str(request.url))\n        logger.info(f\"Successfully downloaded video: {filename}\")\n        return DownloadResponse(**metadata)\n    except ValueError as e:\n        logger.error(f\"Validation error: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Error processing download: {str(e)}\")\n        raise HTTPException(status_code=500, detail=\"Failed to download Instagram content\")\n```\n\n2. Update `main.py` to include the router:\n```python\nfrom fastapi import FastAPI\nfrom fastapi.staticfiles import StaticFiles\nfrom .routers import download\nimport os\nimport logging\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n)\n\n# Create media directory if it doesn't exist\nos.makedirs(\"media\", exist_ok=True)\n\napp = FastAPI(title=\"Instagram Downloader API\")\n\n# Mount the static files directory\napp.mount(\"/static\", StaticFiles(directory=\"media\"), name=\"static\")\n\n# Include routers\napp.include_router(download.router)\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Instagram Downloader API\"}\n```",
        "testStrategy": "1. Test the endpoint with valid Instagram video post URLs\n2. Test with invalid URLs and verify appropriate error responses\n3. Verify the response structure matches the Pydantic schema\n4. Test error handling for various failure scenarios\n5. Check that logging is working correctly",
        "priority": "high",
        "dependencies": [
          2,
          3,
          4
        ],
        "status": "done",
        "subtasks": []
      },
      {
        "id": 6,
        "title": "Implement Error Handling and Logging",
        "description": "Add comprehensive error handling and logging throughout the application to improve reliability and debugging.",
        "details": "1. Create a utility module for logging in `utils/logging.py`:\n```python\nimport logging\nimport json\nfrom fastapi import Request\nimport time\nfrom typing import Callable\nfrom fastapi.middleware.base import BaseHTTPMiddleware\n\n# Configure the logger\ndef setup_logging():\n    logger = logging.getLogger(\"instagram_downloader\")\n    logger.setLevel(logging.INFO)\n    \n    # Create console handler\n    ch = logging.StreamHandler()\n    ch.setLevel(logging.INFO)\n    \n    # Create formatter\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    \n    # Add formatter to ch\n    ch.setFormatter(formatter)\n    \n    # Add ch to logger\n    logger.addHandler(ch)\n    \n    return logger\n\n# Middleware for request logging\nclass LoggingMiddleware(BaseHTTPMiddleware):\n    async def dispatch(self, request: Request, call_next: Callable):\n        start_time = time.time()\n        \n        # Get request details\n        method = request.method\n        url = str(request.url)\n        \n        # Log request\n        logging.info(f\"Request: {method} {url}\")\n        \n        # Process request\n        try:\n            response = await call_next(request)\n            process_time = time.time() - start_time\n            response.headers[\"X-Process-Time\"] = str(process_time)\n            \n            # Log response\n            logging.info(\n                f\"Response: {method} {url} - Status: {response.status_code} - Time: {process_time:.4f}s\"\n            )\n            \n            return response\n        except Exception as e:\n            process_time = time.time() - start_time\n            logging.error(\n                f\"Error: {method} {url} - Error: {str(e)} - Time: {process_time:.4f}s\"\n            )\n            raise\n```\n\n2. Create a custom exception handler in `utils/exceptions.py`:\n```python\nfrom fastapi import Request, HTTPException\nfrom fastapi.responses import JSONResponse\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass InstagramDownloaderException(Exception):\n    def __init__(self, status_code: int, detail: str):\n        self.status_code = status_code\n        self.detail = detail\n        super().__init__(self.detail)\n\nasync def instagram_exception_handler(request: Request, exc: InstagramDownloaderException):\n    logger.error(f\"InstagramDownloaderException: {exc.detail}\")\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\"detail\": exc.detail}\n    )\n\nasync def http_exception_handler(request: Request, exc: HTTPException):\n    logger.error(f\"HTTPException: {exc.detail}\")\n    return JSONResponse(\n        status_code=exc.status_code,\n        content={\"detail\": exc.detail}\n    )\n\nasync def general_exception_handler(request: Request, exc: Exception):\n    logger.error(f\"Unhandled exception: {str(exc)}\")\n    return JSONResponse(\n        status_code=500,\n        content={\"detail\": \"An unexpected error occurred\"}\n    )\n```\n\n3. Update `main.py` to use the middleware and exception handlers:\n```python\nfrom fastapi import FastAPI, HTTPException\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.exceptions import RequestValidationError\nfrom .routers import download\nfrom .utils.logging import setup_logging, LoggingMiddleware\nfrom .utils.exceptions import (\n    InstagramDownloaderException,\n    instagram_exception_handler,\n    http_exception_handler,\n    general_exception_handler\n)\nimport os\n\n# Setup logging\nlogger = setup_logging()\n\n# Create media directory if it doesn't exist\nos.makedirs(\"media\", exist_ok=True)\n\napp = FastAPI(title=\"Instagram Downloader API\")\n\n# Add middleware\napp.add_middleware(LoggingMiddleware)\n\n# Add exception handlers\napp.add_exception_handler(InstagramDownloaderException, instagram_exception_handler)\napp.add_exception_handler(HTTPException, http_exception_handler)\napp.add_exception_handler(Exception, general_exception_handler)\n\n# Mount the static files directory\napp.mount(\"/static\", StaticFiles(directory=\"media\"), name=\"static\")\n\n# Include routers\napp.include_router(download.router)\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Instagram Downloader API\"}\n```",
        "testStrategy": "1. Test error handling by triggering various error conditions\n2. Verify that appropriate HTTP status codes are returned\n3. Check that error details are properly formatted in responses\n4. Verify that all errors are properly logged\n5. Test the logging middleware by making requests and checking logs",
        "priority": "medium",
        "dependencies": [
          1,
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 7,
        "title": "Implement Comments Extraction Functionality",
        "description": "Enhance the Instagram service to extract and return comments from posts, including user information and comment text.",
        "details": "1. Update the `_extract_comments` method in the InstagramService class to handle pagination and rate limiting:\n```python\ndef _extract_comments(self, post: instaloader.Post, max_comments: int = 50) -> List[Dict[str, str]]:\n    \"\"\"Extract comments from a post with pagination support\"\"\"\n    comments = []\n    try:\n        comment_count = 0\n        for comment in post.get_comments():\n            comments.append({\n                \"user\": comment.owner.username,\n                \"text\": comment.text\n            })\n            comment_count += 1\n            if comment_count >= max_comments:\n                break\n                \n            # Add a small delay to avoid rate limiting\n            if comment_count % 10 == 0:\n                time.sleep(0.5)\n                \n    except instaloader.exceptions.ConnectionException:\n        # Handle connection errors gracefully\n        logging.warning(\"Connection error while fetching comments\")\n    except Exception as e:\n        # If comments can't be fetched, log the error\n        logging.error(f\"Error fetching comments: {str(e)}\")\n        \n    return comments\n```\n\n2. Add a parameter to control comment fetching in the download_post method:\n```python\nasync def download_post(self, url: str, fetch_comments: bool = True) -> Tuple[str, Dict[str, Any]]:\n    \"\"\"Download a post and return the file path and metadata\"\"\"\n    try:\n        shortcode = self.extract_shortcode_from_url(url)\n        post = instaloader.Post.from_shortcode(self.loader.context, shortcode)\n        \n        # Generate a unique filename\n        filename = f\"{uuid.uuid4()}.mp4\"\n        filepath = os.path.join(self.media_dir, filename)\n        \n        # Download the video\n        if post.is_video:\n            self.loader.download_post(post, target=self.media_dir)\n            # Rename the downloaded file to our unique filename\n            # Find the video file that was just downloaded\n            for file in os.listdir(self.media_dir):\n                if file.endswith(\".mp4\") and shortcode in file:\n                    os.rename(\n                        os.path.join(self.media_dir, file),\n                        filepath\n                    )\n                    break\n        else:\n            raise ValueError(\"The provided URL does not contain a video\")\n            \n        # Extract metadata\n        metadata = {\n            \"author\": post.owner_username,\n            \"description\": post.caption if post.caption else \"\",\n            \"created_at\": post.date,\n            \"video_url\": f\"/static/{filename}\",\n            \"comments\": self._extract_comments(post) if fetch_comments else []\n        }\n        \n        return filename, metadata\n    except Exception as e:\n        raise Exception(f\"Error downloading Instagram post: {str(e)}\")\n```\n\n3. Update the download endpoint to accept an optional parameter for comments:\n```python\n@router.post(\"/download/\", response_model=DownloadResponse)\nasync def download_instagram_video(\n    request: DownloadRequest, \n    fetch_comments: bool = True,\n    service: InstagramService = Depends(get_instagram_service)\n):\n    try:\n        logger.info(f\"Processing download request for URL: {request.url}\")\n        filename, metadata = await service.download_post(str(request.url), fetch_comments=fetch_comments)\n        logger.info(f\"Successfully downloaded video: {filename}\")\n        return DownloadResponse(**metadata)\n    except ValueError as e:\n        logger.error(f\"Validation error: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logger.error(f\"Error processing download: {str(e)}\")\n        raise HTTPException(status_code=500, detail=\"Failed to download Instagram content\")\n```",
        "testStrategy": "1. Test comment extraction with posts that have varying numbers of comments\n2. Verify that comment data structure matches the expected format\n3. Test with the fetch_comments parameter set to both true and false\n4. Check error handling when comment fetching fails\n5. Test performance with posts that have many comments",
        "priority": "medium",
        "dependencies": [
          3,
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 8,
        "title": "Implement URL Validation and Error Handling",
        "description": "Enhance the URL validation to ensure only valid Instagram post URLs are processed and improve error handling for invalid URLs.",
        "details": "1. Create a more robust URL validator in `utils/validators.py`:\n```python\nimport re\nfrom typing import Optional\nfrom pydantic import validator\nfrom ..utils.exceptions import InstagramDownloaderException\n\ndef validate_instagram_url(url: str) -> str:\n    \"\"\"Validate and normalize Instagram URLs\"\"\"\n    # Strip whitespace and trailing slashes\n    url = url.strip().rstrip('/')\n    \n    # Basic Instagram post URL patterns\n    patterns = [\n        r'^https?://(www\\.)?instagram\\.com/p/[\\w-]+/?.*$',  # Regular post\n        r'^https?://(www\\.)?instagram\\.com/reel/[\\w-]+/?.*$',  # Reels\n        r'^https?://(www\\.)?instagram\\.com/tv/[\\w-]+/?.*$'  # IGTV\n    ]\n    \n    for pattern in patterns:\n        if re.match(pattern, url):\n            return url\n    \n    raise ValueError(\"URL must be a valid Instagram post, reel, or IGTV URL\")\n\ndef extract_shortcode(url: str) -> str:\n    \"\"\"Extract the shortcode from an Instagram URL\"\"\"\n    # Match the shortcode part after /p/, /reel/, or /tv/\n    match = re.search(r'/(p|reel|tv)/([\\w-]+)', url)\n    if match:\n        return match.group(2)\n    raise ValueError(\"Could not extract shortcode from URL\")\n```\n\n2. Update the InstagramService to use the new validators:\n```python\nfrom ..utils.validators import validate_instagram_url, extract_shortcode\n\nclass InstagramService:\n    # ... existing code ...\n    \n    def extract_shortcode_from_url(self, url: str) -> str:\n        # First validate the URL\n        validated_url = validate_instagram_url(url)\n        # Then extract the shortcode\n        return extract_shortcode(validated_url)\n```\n\n3. Update the DownloadRequest schema to use the new validator:\n```python\nfrom pydantic import BaseModel, HttpUrl, validator\nfrom ..utils.validators import validate_instagram_url\n\nclass DownloadRequest(BaseModel):\n    url: HttpUrl\n    \n    @validator('url')\n    def validate_instagram_url(cls, v):\n        return validate_instagram_url(str(v))\n```\n\n4. Enhance error handling in the download endpoint:\n```python\n@router.post(\"/download/\", response_model=DownloadResponse)\nasync def download_instagram_video(\n    request: DownloadRequest, \n    fetch_comments: bool = True,\n    service: InstagramService = Depends(get_instagram_service)\n):\n    try:\n        logger.info(f\"Processing download request for URL: {request.url}\")\n        \n        # Additional validation\n        try:\n            validate_instagram_url(str(request.url))\n        except ValueError as e:\n            raise HTTPException(status_code=400, detail=str(e))\n            \n        filename, metadata = await service.download_post(str(request.url), fetch_comments=fetch_comments)\n        logger.info(f\"Successfully downloaded video: {filename}\")\n        return DownloadResponse(**metadata)\n    except ValueError as e:\n        logger.error(f\"Validation error: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n    except instaloader.exceptions.InstaloaderException as e:\n        logger.error(f\"Instaloader error: {str(e)}\")\n        raise HTTPException(status_code=500, detail=f\"Instagram API error: {str(e)}\")\n    except Exception as e:\n        logger.error(f\"Error processing download: {str(e)}\")\n        raise HTTPException(status_code=500, detail=\"Failed to download Instagram content\")\n```",
        "testStrategy": "1. Test URL validation with various Instagram URL formats (posts, reels, IGTV)\n2. Test with invalid URLs and verify appropriate error responses\n3. Test shortcode extraction from different URL formats\n4. Verify that normalized URLs are handled correctly\n5. Test error handling for various validation failure scenarios",
        "priority": "high",
        "dependencies": [
          2,
          5,
          6
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Implement File Management and Cleanup",
        "description": "Create a system to manage downloaded files, including automatic cleanup of old files to prevent disk space issues.",
        "details": "1. Create a file management service in `services/file_service.py`:\n```python\nimport os\nimport time\nimport shutil\nfrom datetime import datetime, timedelta\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass FileService:\n    def __init__(self, media_dir: str = \"media\", max_age_days: int = 7, max_size_mb: int = 1000):\n        self.media_dir = media_dir\n        self.max_age_days = max_age_days\n        self.max_size_mb = max_size_mb\n        os.makedirs(media_dir, exist_ok=True)\n    \n    def cleanup_old_files(self):\n        \"\"\"Remove files older than max_age_days from the media directory\"\"\"\n        now = time.time()\n        max_age_seconds = self.max_age_days * 24 * 60 * 60\n        removed_count = 0\n        \n        logger.info(f\"Starting cleanup of files older than {self.max_age_days} days\")\n        \n        for filename in os.listdir(self.media_dir):\n            file_path = os.path.join(self.media_dir, filename)\n            if os.path.isfile(file_path):\n                file_age = now - os.path.getmtime(file_path)\n                if file_age > max_age_seconds:\n                    try:\n                        os.remove(file_path)\n                        removed_count += 1\n                    except Exception as e:\n                        logger.error(f\"Error removing {file_path}: {e}\")\n        \n        logger.info(f\"Cleanup completed. Removed {removed_count} files.\")\n        return removed_count\n    \n    def check_disk_usage(self):\n        \"\"\"Check if the media directory exceeds the maximum size\"\"\"\n        total_size = 0\n        for dirpath, _, filenames in os.walk(self.media_dir):\n            for f in filenames:\n                fp = os.path.join(dirpath, f)\n                total_size += os.path.getsize(fp)\n        \n        # Convert to MB\n        total_size_mb = total_size / (1024 * 1024)\n        \n        logger.info(f\"Current media directory size: {total_size_mb:.2f} MB\")\n        \n        if total_size_mb > self.max_size_mb:\n            logger.warning(f\"Media directory exceeds maximum size of {self.max_size_mb} MB\")\n            return True\n        return False\n    \n    def enforce_size_limit(self):\n        \"\"\"Remove oldest files until size is under the limit\"\"\"\n        if not self.check_disk_usage():\n            return 0\n            \n        files = []\n        for filename in os.listdir(self.media_dir):\n            file_path = os.path.join(self.media_dir, filename)\n            if os.path.isfile(file_path):\n                files.append((file_path, os.path.getmtime(file_path)))\n        \n        # Sort by modification time (oldest first)\n        files.sort(key=lambda x: x[1])\n        \n        removed_count = 0\n        for file_path, _ in files:\n            try:\n                os.remove(file_path)\n                removed_count += 1\n                logger.info(f\"Removed {file_path} due to size constraints\")\n                \n                # Check if we're now under the limit\n                if not self.check_disk_usage():\n                    break\n            except Exception as e:\n                logger.error(f\"Error removing {file_path}: {e}\")\n        \n        return removed_count\n```\n\n2. Create a background task for cleanup in `utils/tasks.py`:\n```python\nfrom fastapi import BackgroundTasks\nfrom ..services.file_service import FileService\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ndef cleanup_files_task():\n    \"\"\"Background task to clean up old files\"\"\"\n    try:\n        file_service = FileService()\n        removed_by_age = file_service.cleanup_old_files()\n        removed_by_size = file_service.enforce_size_limit()\n        logger.info(f\"Cleanup task completed. Removed {removed_by_age} old files and {removed_by_size} files due to size constraints.\")\n    except Exception as e:\n        logger.error(f\"Error in cleanup task: {e}\")\n```\n\n3. Update the main.py to run periodic cleanup:\n```python\nfrom fastapi import FastAPI, BackgroundTasks\nfrom .utils.tasks import cleanup_files_task\nimport asyncio\nimport logging\n\n# ... existing code ...\n\n# Background task for periodic cleanup\n@app.on_event(\"startup\")\nasync def startup_event():\n    asyncio.create_task(periodic_cleanup())\n\nasync def periodic_cleanup():\n    \"\"\"Run cleanup task periodically\"\"\"\n    while True:\n        try:\n            logger.info(\"Running scheduled file cleanup\")\n            cleanup_files_task()\n            # Run every 24 hours\n            await asyncio.sleep(24 * 60 * 60)\n        except Exception as e:\n            logger.error(f\"Error in periodic cleanup: {e}\")\n            # Wait a bit before retrying\n            await asyncio.sleep(60 * 60)\n```\n\n4. Add a background task to the download endpoint:\n```python\n@router.post(\"/download/\", response_model=DownloadResponse)\nasync def download_instagram_video(\n    request: DownloadRequest,\n    background_tasks: BackgroundTasks,\n    fetch_comments: bool = True,\n    service: InstagramService = Depends(get_instagram_service)\n):\n    try:\n        # ... existing code ...\n        \n        # Add cleanup task to run after response\n        background_tasks.add_task(cleanup_files_task)\n        \n        return DownloadResponse(**metadata)\n    except Exception as e:\n        # ... existing error handling ...\n```",
        "testStrategy": "1. Test file cleanup by creating files with different timestamps\n2. Verify that files older than the maximum age are removed\n3. Test disk usage enforcement by creating large files\n4. Verify that oldest files are removed first when enforcing size limits\n5. Test the background task functionality\n6. Verify that cleanup doesn't interfere with active downloads",
        "priority": "medium",
        "dependencies": [
          4
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Add API Documentation",
        "description": "Implement comprehensive API documentation using FastAPI's built-in Swagger UI and ReDoc support.",
        "details": "1. Enhance the FastAPI application with detailed documentation in `main.py`:\n```python\nfrom fastapi import FastAPI\nfrom fastapi.openapi.utils import get_openapi\n\napp = FastAPI(\n    title=\"Instagram Downloader API\",\n    description=\"A REST API service for downloading videos from Instagram posts and extracting metadata\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\",\n    openapi_url=\"/openapi.json\"\n)\n\ndef custom_openapi():\n    if app.openapi_schema:\n        return app.openapi_schema\n    \n    openapi_schema = get_openapi(\n        title=\"Instagram Downloader API\",\n        version=\"1.0.0\",\n        description=\"A REST API service for downloading videos from Instagram posts and extracting metadata. This API allows developers to easily integrate Instagram content into their applications.\",\n        routes=app.routes,\n    )\n    \n    # Add additional information\n    openapi_schema[\"info\"][\"x-logo\"] = {\n        \"url\": \"https://fastapi.tiangolo.com/img/logo-margin/logo-teal.png\"\n    }\n    \n    app.openapi_schema = openapi_schema\n    return app.openapi_schema\n\napp.openapi = custom_openapi\n```\n\n2. Add detailed documentation to the endpoint in `routers/download.py`:\n```python\n@router.post(\n    \"/download/\", \n    response_model=DownloadResponse,\n    summary=\"Download Instagram Video\",\n    description=\"Downloads a video from an Instagram post URL and returns metadata including author, description, creation date, and comments.\",\n    response_description=\"Video metadata and download URL\",\n    status_code=200\n)\nasync def download_instagram_video(\n    request: DownloadRequest,\n    background_tasks: BackgroundTasks,\n    fetch_comments: bool = Query(\n        True, \n        description=\"Whether to fetch and include comments in the response\"\n    ),\n    service: InstagramService = Depends(get_instagram_service)\n):\n    \"\"\"Download a video from Instagram and extract metadata.\n    \n    - **url**: A valid Instagram post URL containing a video\n    - **fetch_comments**: Set to false to skip fetching comments (faster response)\n    \n    Returns a JSON object with:\n    - author: Instagram username of the post creator\n    - description: Post caption/description\n    - created_at: Post creation timestamp\n    - video_url: URL to download the video file\n    - comments: Array of comment objects with user and text fields\n    \"\"\"\n    try:\n        # ... existing code ...\n```\n\n3. Add examples to the Pydantic models in `schemas/requests.py` and `schemas/responses.py`:\n```python\nclass DownloadRequest(BaseModel):\n    url: HttpUrl\n    \n    @validator('url')\n    def validate_instagram_url(cls, v):\n        return validate_instagram_url(str(v))\n    \n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"url\": \"https://www.instagram.com/p/CdEfGhIjKlM/\"\n            }\n        }\n\nclass DownloadResponse(BaseModel):\n    author: str\n    description: Optional[str] = None\n    created_at: datetime\n    video_url: str\n    comments: Optional[List[CommentModel]] = []\n    \n    class Config:\n        schema_extra = {\n            \"example\": {\n                \"author\": \"instagram_user\",\n                \"description\": \"Check out this amazing video!\",\n                \"created_at\": \"2023-01-15T12:30:45\",\n                \"video_url\": \"/static/a1b2c3d4-e5f6-7890-abcd-ef1234567890.mp4\",\n                \"comments\": [\n                    {\"user\": \"commenter1\", \"text\": \"Great video!\"},\n                    {\"user\": \"commenter2\", \"text\": \"Thanks for sharing!\"}\n                ]\n            }\n        }\n```\n\n4. Create a simple HTML landing page in `static/index.html` to provide basic usage information:\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Instagram Downloader API</title>\n    <style>\n        body {\n            font-family: Arial, sans-serif;\n            line-height: 1.6;\n            max-width: 800px;\n            margin: 0 auto;\n            padding: 20px;\n        }\n        code {\n            background-color: #f4f4f4;\n            padding: 2px 5px;\n            border-radius: 3px;\n        }\n        pre {\n            background-color: #f4f4f4;\n            padding: 10px;\n            border-radius: 5px;\n            overflow-x: auto;\n        }\n    </style>\n</head>\n<body>\n    <h1>Instagram Downloader API</h1>\n    <p>A REST API service for downloading videos from Instagram posts and extracting metadata.</p>\n    \n    <h2>Documentation</h2>\n    <p>Full API documentation is available at:</p>\n    <ul>\n        <li><a href=\"/docs\">Swagger UI</a> - Interactive API documentation</li>\n        <li><a href=\"/redoc\">ReDoc</a> - Alternative API documentation</li>\n    </ul>\n    \n    <h2>Basic Usage</h2>\n    <p>To download a video from Instagram, send a POST request to the <code>/api/download/</code> endpoint with a JSON body containing the Instagram post URL:</p>\n    \n    <pre>curl -X POST \"http://localhost:8000/api/download/\" \\\n-H \"Content-Type: application/json\" \\\n-d '{\"url\": \"https://www.instagram.com/p/CdEfGhIjKlM/\"}'</pre>\n</body>\n</html>\n```\n\n5. Update the root endpoint to redirect to the documentation:\n```python\n@app.get(\"/\", include_in_schema=False)\nasync def root():\n    return RedirectResponse(url=\"/docs\")\n```",
        "testStrategy": "1. Verify that the Swagger UI is accessible at /docs\n2. Check that the ReDoc documentation is accessible at /redoc\n3. Test that all endpoints are properly documented\n4. Verify that examples are displayed correctly\n5. Test the landing page and ensure it provides useful information\n6. Check that the API schema is correctly generated at /openapi.json",
        "priority": "low",
        "dependencies": [
          5
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Implement Unit and Integration Tests",
        "description": "Create comprehensive test suite including unit tests for individual components and integration tests for the full API.",
        "details": "1. Create a test directory structure:\n```\ntests/\n  __init__.py\n  test_validators.py\n  test_instagram_service.py\n  test_file_service.py\n  test_api.py\n  conftest.py\n```\n\n2. Create a conftest.py file with fixtures:\n```python\nimport pytest\nfrom fastapi.testclient import TestClient\nimport os\nimport shutil\nfrom app.main import app\n\n@pytest.fixture\ndef client():\n    \"\"\"Create a test client for the FastAPI app\"\"\"\n    with TestClient(app) as client:\n        yield client\n\n@pytest.fixture\ndef test_media_dir():\n    \"\"\"Create a temporary media directory for tests\"\"\"\n    test_dir = \"test_media\"\n    os.makedirs(test_dir, exist_ok=True)\n    yield test_dir\n    # Cleanup after tests\n    shutil.rmtree(test_dir)\n```\n\n3. Create validator tests in test_validators.py:\n```python\nimport pytest\nfrom app.utils.validators import validate_instagram_url, extract_shortcode\n\ndef test_validate_instagram_url_valid():\n    \"\"\"Test that valid Instagram URLs pass validation\"\"\"\n    valid_urls = [\n        \"https://www.instagram.com/p/ABC123/\",\n        \"https://instagram.com/p/ABC123\",\n        \"http://www.instagram.com/p/ABC123/\",\n        \"https://www.instagram.com/reel/ABC123/\",\n        \"https://www.instagram.com/tv/ABC123/\"\n    ]\n    \n    for url in valid_urls:\n        assert validate_instagram_url(url) == url.rstrip('/')\n\ndef test_validate_instagram_url_invalid():\n    \"\"\"Test that invalid Instagram URLs fail validation\"\"\"\n    invalid_urls = [\n        \"https://www.instagram.com/\",\n        \"https://www.instagram.com/explore/\",\n        \"https://www.facebook.com/p/ABC123/\",\n        \"https://www.instagram.com/user/ABC123/\",\n        \"not a url\"\n    ]\n    \n    for url in invalid_urls:\n        with pytest.raises(ValueError):\n            validate_instagram_url(url)\n\ndef test_extract_shortcode():\n    \"\"\"Test shortcode extraction from URLs\"\"\"\n    test_cases = [\n        (\"https://www.instagram.com/p/ABC123/\", \"ABC123\"),\n        (\"https://instagram.com/p/ABC123\", \"ABC123\"),\n        (\"https://www.instagram.com/reel/DEF456/\", \"DEF456\"),\n        (\"https://www.instagram.com/tv/GHI789/\", \"GHI789\")\n    ]\n    \n    for url, expected in test_cases:\n        assert extract_shortcode(url) == expected\n\ndef test_extract_shortcode_invalid():\n    \"\"\"Test shortcode extraction from invalid URLs\"\"\"\n    invalid_urls = [\n        \"https://www.instagram.com/\",\n        \"https://www.instagram.com/explore/\",\n        \"not a url\"\n    ]\n    \n    for url in invalid_urls:\n        with pytest.raises(ValueError):\n            extract_shortcode(url)\n```\n\n4. Create API tests in test_api.py:\n```python\nimport pytest\nfrom fastapi.testclient import TestClient\nfrom unittest.mock import patch, MagicMock\nfrom datetime import datetime\n\ndef test_root_redirect(client):\n    \"\"\"Test that the root endpoint redirects to docs\"\"\"\n    response = client.get(\"/\")\n    assert response.status_code == 307\n    assert response.headers[\"location\"] == \"/docs\"\n\ndef test_download_endpoint_validation(client):\n    \"\"\"Test URL validation in the download endpoint\"\"\"\n    # Test with invalid URL\n    response = client.post(\n        \"/api/download/\",\n        json={\"url\": \"https://www.instagram.com/\"}\n    )\n    assert response.status_code == 400\n    assert \"valid Instagram\" in response.json()[\"detail\"]\n    \n    # Test with non-Instagram URL\n    response = client.post(\n        \"/api/download/\",\n        json={\"url\": \"https://www.example.com/p/123\"}\n    )\n    assert response.status_code == 400\n\n@patch(\"app.services.instagram_service.InstagramService.download_post\")\ndef test_download_endpoint_success(mock_download, client):\n    \"\"\"Test successful download with mocked Instagram service\"\"\"\n    # Mock the download_post method\n    mock_download.return_value = (\"test_file.mp4\", {\n        \"author\": \"test_user\",\n        \"description\": \"Test description\",\n        \"created_at\": datetime.now(),\n        \"video_url\": \"/static/test_file.mp4\",\n        \"comments\": [{\"user\": \"commenter\", \"text\": \"Great!\"}]\n    })\n    \n    # Test with valid URL\n    response = client.post(\n        \"/api/download/\",\n        json={\"url\": \"https://www.instagram.com/p/ABC123/\"}\n    )\n    \n    assert response.status_code == 200\n    data = response.json()\n    assert data[\"author\"] == \"test_user\"\n    assert data[\"description\"] == \"Test description\"\n    assert data[\"video_url\"] == \"/static/test_file.mp4\"\n    assert len(data[\"comments\"]) == 1\n    assert data[\"comments\"][0][\"user\"] == \"commenter\"\n```\n\n5. Create a pytest.ini file in the project root:\n```ini\n[pytest]\npythonpath = .\naddopts = -v\ntestpaths = tests\n```\n\n6. Add a test command to the project:\n```python\n# In setup.py or as a script\n\n# Command to run tests\n# pytest tests/\n```",
        "testStrategy": "1. Run the unit tests for individual components\n2. Run integration tests for the API endpoints\n3. Verify that all tests pass and provide good coverage\n4. Test edge cases and error handling\n5. Use mocks to isolate components during testing\n6. Verify that the test fixtures work correctly",
        "priority": "medium",
        "dependencies": [
          3,
          5,
          6,
          8
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Create Deployment Configuration",
        "description": "Prepare the application for deployment with Docker configuration and production settings.",
        "details": "1. Create a Dockerfile in the project root:\n```dockerfile\nFROM python:3.9-slim\n\nWORKDIR /app\n\n# Install dependencies\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY . .\n\n# Create media directory\nRUN mkdir -p media && chmod 777 media\n\n# Expose port\nEXPOSE 8000\n\n# Run the application\nCMD [\"uvicorn\", \"app.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```\n\n2. Create a docker-compose.yml file:\n```yaml\nversion: '3'\n\nservices:\n  api:\n    build: .\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - ./media:/app/media\n    restart: unless-stopped\n    environment:\n      - MAX_MEDIA_AGE_DAYS=7\n      - MAX_MEDIA_SIZE_MB=1000\n```\n\n3. Create a production configuration file in `app/config.py`:\n```python\nimport os\nfrom pydantic import BaseSettings\n\nclass Settings(BaseSettings):\n    # API settings\n    API_TITLE: str = \"Instagram Downloader API\"\n    API_DESCRIPTION: str = \"A REST API service for downloading videos from Instagram posts\"\n    API_VERSION: str = \"1.0.0\"\n    \n    # Media settings\n    MEDIA_DIR: str = \"media\"\n    MAX_MEDIA_AGE_DAYS: int = int(os.getenv(\"MAX_MEDIA_AGE_DAYS\", \"7\"))\n    MAX_MEDIA_SIZE_MB: int = int(os.getenv(\"MAX_MEDIA_SIZE_MB\", \"1000\"))\n    \n    # Instagram settings\n    INSTAGRAM_DELAY: float = 1.0  # Delay between requests to avoid rate limiting\n    MAX_COMMENTS: int = 50\n    \n    class Config:\n        env_file = \".env\"\n\nsettings = Settings()\n```\n\n4. Update the main.py file to use the settings:\n```python\nfrom fastapi import FastAPI\nfrom fastapi.staticfiles import StaticFiles\nfrom .config import settings\nimport os\n\n# Create media directory if it doesn't exist\nos.makedirs(settings.MEDIA_DIR, exist_ok=True)\n\napp = FastAPI(\n    title=settings.API_TITLE,\n    description=settings.API_DESCRIPTION,\n    version=settings.API_VERSION\n)\n\n# Mount the static files directory\napp.mount(\"/static\", StaticFiles(directory=settings.MEDIA_DIR), name=\"static\")\n```\n\n5. Create a .env.example file:\n```\n# API settings\nAPI_TITLE=Instagram Downloader API\nAPI_DESCRIPTION=A REST API service for downloading videos from Instagram posts\nAPI_VERSION=1.0.0\n\n# Media settings\nMEDIA_DIR=media\nMAX_MEDIA_AGE_DAYS=7\nMAX_MEDIA_SIZE_MB=1000\n\n# Instagram settings\nINSTAGRAM_DELAY=1.0\nMAX_COMMENTS=50\n```\n\n6. Create a simple deployment script in `scripts/deploy.sh`:\n```bash\n#!/bin/bash\n\n# Build and deploy the Docker container\necho \"Building Docker image...\"\ndocker-compose build\n\necho \"Starting services...\"\ndocker-compose up -d\n\necho \"Deployment complete!\"\necho \"API is available at http://localhost:8000\"\necho \"Documentation is available at http://localhost:8000/docs\"\n```\n\n7. Create a .dockerignore file:\n```\n.git\n.gitignore\n.env\n__pycache__/\n*.py[cod]\n*$py.class\n*.so\n.Python\nenv/\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\n*.egg-info/\n.installed.cfg\n*.egg\nmedia/*\ntest_media/\ntests/\n```",
        "testStrategy": "1. Build the Docker image and verify it runs correctly\n2. Test the application with the Docker configuration\n3. Verify that environment variables are correctly loaded\n4. Test the deployment script\n5. Check that volumes are correctly mounted for media storage\n6. Verify that the application can be accessed at the expected URL",
        "priority": "low",
        "dependencies": [
          1,
          4,
          9
        ],
        "status": "pending",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Enhance Instagram Downloader Service with Advanced Features",
        "description": "Improve the Instagram Downloader service with file logging, session management, unique video naming, caching, complete metadata extraction, and optimized API responses for both public and private content.",
        "details": "1. Update the logging configuration to use file-based logging instead of console output:\n```python\nimport logging\nfrom logging.handlers import RotatingFileHandler\nimport os\n\ndef setup_logging():\n    log_dir = \"logs\"\n    os.makedirs(log_dir, exist_ok=True)\n    \n    # Configure root logger\n    logger = logging.getLogger()\n    logger.setLevel(logging.INFO)\n    \n    # Remove any existing handlers (like console handlers)\n    for handler in logger.handlers[:]:\n        logger.removeHandler(handler)\n    \n    # Create rotating file handler\n    file_handler = RotatingFileHandler(\n        os.path.join(log_dir, \"instagram_downloader.log\"),\n        maxBytes=10*1024*1024,  # 10MB\n        backupCount=5\n    )\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    file_handler.setFormatter(formatter)\n    logger.addHandler(file_handler)\n```\n\n2. Enhance the InstagramService class to ensure proper session management:\n```python\nclass InstagramService:\n    def __init__(self, media_dir: str = \"media\"):\n        self.media_dir = media_dir\n        os.makedirs(media_dir, exist_ok=True)\n        self._session = None\n        self._cache = {}  # In-memory cache for quick responses\n        \n    def _get_session(self):\n        \"\"\"Get or create an authenticated Instaloader session\"\"\"\n        if self._session is None:\n            self._session = instaloader.Instaloader(\n                download_videos=True,\n                download_video_thumbnails=False,\n                download_geotags=False,\n                download_comments=False,\n                save_metadata=True,\n                quiet=True\n            )\n            \n            # Load saved session if available\n            session_file = \"session-username\"  # Replace with actual username\n            try:\n                self._session.load_session_from_file(session_file)\n                logging.info(\"Successfully loaded saved Instagram session\")\n            except Exception as e:\n                logging.error(f\"Failed to load Instagram session: {str(e)}\")\n                raise InstagramDownloaderException(\"Authentication failed: Could not load saved session\")\n                \n        return self._session\n```\n\n3. Modify the download method to use shortcode as the filename and implement caching:\n```python\ndef download_post(self, url: str) -> Dict[str, Any]:\n    \"\"\"Download a post and return metadata\"\"\"\n    shortcode = self._extract_shortcode(url)\n    \n    # Check cache first\n    if shortcode in self._cache:\n        logging.info(f\"Returning cached result for shortcode: {shortcode}\")\n        return self._cache[shortcode]\n    \n    try:\n        # Get authenticated session\n        loader = self._get_session()\n        \n        # Get post by shortcode\n        post = instaloader.Post.from_shortcode(loader.context, shortcode)\n        \n        # Check if it's a video\n        if not post.is_video:\n            raise InstagramDownloaderException(\"The provided URL is not a video post\")\n        \n        # Create filename using shortcode\n        video_filename = f\"{shortcode}.mp4\"\n        video_path = os.path.join(self.media_dir, video_filename)\n        \n        # Download only if not already exists\n        if not os.path.exists(video_path):\n            # Custom download to save with shortcode filename\n            loader.download_post(post, target=self.media_dir)\n            \n            # Rename the downloaded file to use shortcode\n            old_filename = None\n            for file in os.listdir(self.media_dir):\n                if file.endswith(\".mp4\") and shortcode in file:\n                    old_filename = file\n                    break\n                    \n            if old_filename and old_filename != video_filename:\n                os.rename(\n                    os.path.join(self.media_dir, old_filename),\n                    video_path\n                )\n        \n        # Extract full metadata\n        result = {\n            \"author\": post.owner_username,\n            \"description\": post.caption if post.caption else \"\",\n            \"created_at\": post.date_utc.isoformat(),\n            \"video_url\": f\"/media/{video_filename}\"\n        }\n        \n        # Cache the result\n        self._cache[shortcode] = result\n        \n        return result\n    except Exception as e:\n        logging.error(f\"Error downloading post {shortcode}: {str(e)}\")\n        raise InstagramDownloaderException(f\"Failed to download post: {str(e)}\")\n```\n\n4. Update the API endpoint to return only the required fields:\n```python\n@router.post(\"/download\", response_model=DownloadResponse)\nasync def download_video(request: DownloadRequest, service: InstagramService = Depends(get_instagram_service)):\n    try:\n        result = service.download_post(request.url)\n        return {\n            \"author\": result[\"author\"],\n            \"description\": result[\"description\"],\n            \"created_at\": result[\"created_at\"],\n            \"video_url\": result[\"video_url\"]\n        }\n    except InstagramDownloaderException as e:\n        logging.error(f\"Download failed: {str(e)}\")\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception as e:\n        logging.error(f\"Unexpected error: {str(e)}\")\n        raise HTTPException(status_code=500, detail=\"Internal server error\")\n```\n\n5. Update the DownloadResponse schema to match the required fields:\n```python\nclass DownloadResponse(BaseModel):\n    author: str\n    description: str\n    created_at: str\n    video_url: str\n```\n\n6. Implement a cache cleanup mechanism to prevent unlimited growth:\n```python\ndef cleanup_cache(self, max_items: int = 1000):\n    \"\"\"Remove oldest items from cache if it exceeds max size\"\"\"\n    if len(self._cache) > max_items:\n        # Sort by access time and remove oldest\n        items_to_remove = len(self._cache) - max_items\n        logging.info(f\"Cleaning up cache, removing {items_to_remove} items\")\n        # Implementation depends on how you track access time\n```",
        "testStrategy": "1. Test file logging configuration:\n   - Verify that logs are written to the specified log file\n   - Check that no logs appear in the console\n   - Test log rotation by generating sufficient log volume\n   - Verify that different log levels are correctly recorded\n\n2. Test session management:\n   - Verify that the service can load a pre-authenticated session\n   - Test error handling when session file is missing or invalid\n   - Confirm that 2FA-authenticated sessions work correctly\n   - Test session persistence across multiple requests\n\n3. Test video naming and storage:\n   - Verify that videos are saved with the format \"{shortcode}.mp4\"\n   - Test with various post types to ensure consistent naming\n   - Check that duplicate downloads don't create multiple files\n   - Verify file permissions are correct for the saved videos\n\n4. Test caching functionality:\n   - Measure response time for initial request vs. cached request\n   - Verify that cached responses return identical data\n   - Test cache behavior with a large number of different posts\n   - Confirm that cache is properly invalidated when needed\n\n5. Test metadata extraction:\n   - Verify that the full caption/description is returned\n   - Test with posts containing long descriptions and special characters\n   - Check that created_at timestamp is correctly formatted\n   - Verify author information is correctly extracted\n\n6. Test API response format:\n   - Confirm that responses only contain the required fields (author, description, created_at, video_url)\n   - Verify that all fields contain the expected data types\n   - Test with various post types to ensure consistent response format\n   - Check error responses for invalid requests\n\n7. Test with both public and private content:\n   - Test downloading from public Instagram accounts\n   - Verify functionality with private accounts (using authenticated session)\n   - Test error handling for unauthorized access attempts\n   - Verify appropriate error messages for inaccessible content",
        "status": "pending",
        "dependencies": [
          3,
          5,
          8
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement File-Based Logging Configuration",
            "description": "Update the logging system to use file-based logging with rotation instead of console output to improve debugging and monitoring capabilities.",
            "dependencies": [],
            "details": "Create a setup_logging function that configures a RotatingFileHandler to write logs to a file in a 'logs' directory. The handler should support log rotation with a maximum file size of 10MB and keep 5 backup files. The log format should include timestamp, logger name, level, and message. Make sure to remove any existing console handlers and set the appropriate log level.",
            "status": "pending",
            "testStrategy": "Verify logs are written to the specified file and not to console. Test log rotation by generating sufficient log volume. Check that different log levels are correctly recorded."
          },
          {
            "id": 2,
            "title": "Enhance Session Management for Instagram API",
            "description": "Improve the InstagramService class to properly manage Instaloader sessions, including loading saved sessions to avoid authentication issues.",
            "dependencies": [
              "13.1"
            ],
            "details": "Modify the InstagramService class to implement a _get_session method that creates and configures an Instaloader instance with appropriate settings. Add functionality to load a saved session from a file if available. Implement proper error handling and logging for session management failures. The session should be stored as an instance variable to avoid creating multiple sessions.",
            "status": "pending",
            "testStrategy": "Test session creation and loading with both valid and invalid session files. Verify that session persistence works across multiple requests. Check error handling when session loading fails."
          },
          {
            "id": 3,
            "title": "Implement Shortcode-Based File Naming and Caching",
            "description": "Modify the download functionality to use Instagram shortcodes for file naming and implement an in-memory cache to improve performance for repeated requests.",
            "dependencies": [
              "13.2"
            ],
            "details": "Update the download_post method to extract shortcodes from URLs and use them as filenames for downloaded videos. Implement an in-memory cache using a dictionary to store results keyed by shortcode. Before downloading, check if the shortcode exists in the cache or if the file already exists on disk. When downloading, ensure proper renaming of files to match the shortcode format. Add logging for cache hits and download operations.",
            "status": "pending",
            "testStrategy": "Test cache hits with repeated requests for the same URL. Verify that files are correctly named using shortcodes. Test the download process with both new and existing videos. Check that the cache correctly returns previously downloaded content."
          },
          {
            "id": 4,
            "title": "Implement Cache Cleanup Mechanism",
            "description": "Create a cache management system to prevent unlimited growth of the in-memory cache by removing oldest items when the cache exceeds a specified size.",
            "dependencies": [
              "13.3"
            ],
            "details": "Implement a cleanup_cache method in the InstagramService class that removes the oldest items from the cache when it exceeds a maximum size (default 1000 items). Add timestamp tracking to cache entries to determine which items are oldest. Call this cleanup method periodically, such as after each new cache addition. Add logging for cache cleanup operations.",
            "status": "pending",
            "testStrategy": "Test that the cache correctly removes oldest items when exceeding the maximum size. Verify that frequently accessed items are retained. Check that the cleanup process doesn't affect ongoing operations."
          },
          {
            "id": 5,
            "title": "Enhance Metadata Extraction and Storage",
            "description": "Improve the metadata extraction process to capture complete post information, including saving the full caption to a text file alongside the video.",
            "dependencies": [
              "13.3"
            ],
            "details": "Extend the download_post method to extract comprehensive metadata from Instagram posts. Save the full caption to a .txt file with the same base name as the video file. Include additional metadata fields such as like count, view count, and hashtags in the returned data structure. Ensure all metadata is properly cached along with the video URL.",
            "status": "pending",
            "testStrategy": "Verify that caption text files are correctly created and contain the full post text. Test with posts containing various metadata elements (hashtags, mentions, emojis). Check that all expected metadata fields are returned in the response."
          },
          {
            "id": 6,
            "title": "Optimize API Response Structure",
            "description": "Update the API endpoint to return a simplified and consistent response structure with only the required fields for client consumption.",
            "dependencies": [
              "13.5"
            ],
            "details": "Modify the download_video endpoint to transform the internal metadata structure into a clean, consistent response format. Update the DownloadResponse Pydantic model to include only the necessary fields: author, description, created_at, and video_url. Ensure proper error handling with appropriate HTTP status codes and error messages. Add logging for API requests and responses.",
            "status": "pending",
            "testStrategy": "Test the API endpoint with various valid and invalid requests. Verify that the response structure matches the defined schema. Check error responses for different failure scenarios. Test with both cached and non-cached content."
          },
          {
            "id": 7,
            "title": "Test Public and Private Content Handling",
            "description": "Implement comprehensive testing for both public and private Instagram content to ensure the service works correctly with different content types.",
            "dependencies": [
              "13.6"
            ],
            "details": "Create a test suite that verifies the service's ability to handle both public and private Instagram content. For private content, ensure the session management correctly uses authenticated sessions. Test error handling for unauthorized access attempts. Implement test cases for various content types (posts, reels, IGTV). Document the testing process and results.",
            "status": "pending",
            "testStrategy": "Test with at least two different Instagram URLs - one public and one from a private account. Verify that authentication works correctly for private content. Check that all features (caching, metadata extraction, file naming) work consistently for both content types. Test error scenarios such as deleted posts or invalid URLs."
          }
        ]
      }
    ],
    "metadata": {
      "created": "2025-09-30T10:19:17.358Z",
      "updated": "2025-09-30T12:52:26.147Z",
      "description": "Tasks for master context"
    }
  }
}